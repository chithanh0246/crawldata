import asyncio
from unittest import result

import pandas as pd
from pyppeteer import launch
async def main():
    print('nhập tên file:')
    filename= input()
    browser = await launch({'headless' :False})
    page = await browser.newPage()
    link="https://www.facebook.com/ads/library/?active_status=active&ad_type=all&country=VN&q=%22b%E1%BA%A5t%20%C4%91%E1%BB%99ng%20s%E1%BA%A3n%22%20%22ngh%E1%BB%89%20d%C6%B0%E1%BB%A1ng%22&sort_data[direction]=desc&sort_data[mode]=relevancy_monthly_grouped&search_type=keyword_exact_phrase&media_type=all"
    await page.goto(link)
    result=[]
    # hover last page
    await page.waitFor(2000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    await page.hover('.q6ul9yy4 > .s4swhuz0')
    await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)
    # await page.hover('.q6ul9yy4 > .s4swhuz0')
    # await page.waitFor(6000)

    # await page.screenshot({
    # 'path': 'testim.png','fullPage': True
    # })

    #get element page
    list_button_detail = await page.querySelectorAll('.orx9ay3o ._99s5 > ._9b9p')
    for line in list_button_detail:
        # get element ads id
        ads_id = await line.querySelector('._99s5 .fxk3tzhb .s4swhuz0 .aglvbi8b .j1p9ls3c')
        #get
        link = await line.querySelector('.orx9ay3o ._99s5 ._3qn7:nth-child(1) ._3qn7:nth-child(1) .aglvbi8b .aglvbi8b .rse6dlih')
        name = await line.querySelector('.orx9ay3o ._99s5 ._3qn7:nth-child(1) ._3qn7:nth-child(1) .aglvbi8b .aglvbi8b .rse6dlih .j1p9ls3c')
        content = await line.querySelector('.orx9ay3o ._99s5 .ta68dy8c:nth-child(2) ._4ik4:nth-child(1) > div:nth-child(1)')
        date = await line.querySelector('.orx9ay3o ._99s5 .fxk3tzhb:nth-child(2) > .j1p9ls3c')
        id =await page.evaluate('(e)=> e.textContent',ads_id)
        if(link is None or content is None):
            continue
        linkpage = await page.evaluate('''(e)=> e.getAttribute('href')''',link)
        startdate = await page.evaluate('(e)=> e.textContent',date)
        content_page = await page.evaluate('(e)=> e.textContent',content)
        name_page = await page.evaluate('(e)=> e.textContent',name) 

        result.append({'namepage': name_page,'start date': startdate,'link page':linkpage,'link ads': 'https://www.facebook.com/ads/library/?id='+id.split('ID: ')[1],'post content':content_page})
    df = pd.DataFrame(result)
    df.to_csv(r'D:\crawlfacebook\version1\fileroot\%s.csv'%filename,index=False)
    notin=df[df['namepage'].str.contains('tuyển|tuyển dụng|ứng tuyển',case=False)|df['post content'].str.contains('tuyển|tuyển dụng|ứng tuyển',case=False)]['namepage'].tolist()
    df2=df[~df['namepage'].isin(notin)]
    df2.to_csv(r'D:\crawlfacebook\version1\filefillter\%scontains.csv'%filename,index=False)

    await browser.close()
asyncio.get_event_loop().run_until_complete(main())